{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#worst case for calculate Loss\n",
    "def hinge_loss(X, y, w):\n",
    "    \"\"\"\n",
    "    Compute Hinge Loss for multi-class classification.\n",
    "    \n",
    "    :param X: Input data (n, d)\n",
    "    :param y: True labels (n,)\n",
    "    :param w: Weights (d, c)\n",
    "    :return: Scalar loss value\n",
    "    \"\"\"\n",
    "    n, c = X.shape[0], w.shape[1]\n",
    "    \n",
    "    # Compute the scores (raw model outputs)\n",
    "    scores = np.dot(X, w)  # (n, c)\n",
    "    \n",
    "    # Compute Hinge Loss\n",
    "    loss = 0\n",
    "    for i in range(1000):\n",
    "        correct_class_score = scores[i, y[i]]  # Score for the correct class\n",
    "        for j in range(c):\n",
    "            if j != y[i]:  # For all classes except the correct one\n",
    "                loss += max(0, 1 - correct_class_score + scores[i, j])  # Hinge Loss\n",
    "\n",
    "    # Average the loss\n",
    "    loss /= n\n",
    "    return loss\n",
    "\n",
    "# Random initialization of data\n",
    "np.random.seed(0)\n",
    "n_samples = 10000\n",
    "n_features = 3073\n",
    "n_classes = 10\n",
    "\n",
    "X_train = np.random.randn(n_samples, n_features)  # Input data\n",
    "y_train = np.random.randint(0, n_classes, size=n_samples)  # Random labels\n",
    "\n",
    "# Searching for weights with the lowest loss\n",
    "best_loss = float(\"inf\")\n",
    "best_W = None\n",
    "\n",
    "for i in range(10000):\n",
    "    w = np.random.randn(n_features, n_classes) * 0.0001  # Random initialization of weights\n",
    "    loss = hinge_loss(X_train, y_train, w)  # Compute the loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_W = w\n",
    "    print(\"In attempt %d the loss was %f, best %f\" % (i, loss, best_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi calss SVM Loss function\n",
    "\n",
    "def L_i_vectorized(x, y, W):\n",
    "    scores = W.dot(x)\n",
    "    margins = np.maximum(0, scores - scores[y] + 1)\n",
    "    margins[y] = 0\n",
    "    loss_i = np.sum(margins)\n",
    "    return loss_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Numerical gradient\n",
    "def eval_numerical_gradient(f, x):\n",
    "    \"\"\"\n",
    "    A function to compute the numerical gradient of a function f at the point x using finite differences.\n",
    "    \n",
    "    :param f: The function to compute the gradient for.\n",
    "    :param x: The point (numpy array) at which the gradient is computed.\n",
    "    :return: The gradient (numpy array) at the point x.\n",
    "    \"\"\"\n",
    "    fx = f(x)  # Compute the value of the function at x\n",
    "    grad = np.zeros_like(x)  # Initialize the gradient array (same shape as x)\n",
    "    h = 0.00001  # Small step size for finite difference\n",
    "\n",
    "    # Use np.nditer to iterate over all elements of x (supporting multi-dimensional arrays)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        ix = it.multi_index  # Get the index of the current element\n",
    "        old_value = x[ix]  # Save the original value of x[ix]\n",
    "        \n",
    "        # Evaluate f(x + h) by adding a small step to the current element\n",
    "        x[ix] += h\n",
    "        fxh = f(x)  # Compute the function value at x + h\n",
    "        \n",
    "        # Restore the original value of x[ix]\n",
    "        x[ix] = old_value\n",
    "\n",
    "        # Compute the partial derivative using the finite difference method\n",
    "        grad[ix] = (fxh - fx) / h\n",
    "        \n",
    "        it.iternext()  # Move to the next element\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "#Numerical gradient: Approximate, time-consuming, easy to implement!\n",
    "#Analytical gradient: Accurate, fast, prone to implementation errors!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice:\n",
    "\n",
    "We always use the analytical gradient.\n",
    "However, to ensure the correctness of the implementation, we compare the analytical gradient with the numerical gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Gradient Descent Implementation\n",
    "\n",
    "# Set the condition for continuous updates (e.g., you can break this when convergence is met)\n",
    "##while True:\n",
    "    # Calculate the gradient of the loss function with respect to the weights\n",
    "    # 'evaluate_gradient' is a placeholder for the gradient calculation function\n",
    "    ##gradient = evaluate_gradient(lossfun, data, weights)\n",
    "    \n",
    "    # Update the weights by subtracting the gradient (scaled by the learning rate/step size)\n",
    "    ##weights += -step_size * gradient  # Gradient descent update rule\n",
    "\n",
    "    # Optional: Add a stopping condition based on a maximum number of iterations or convergence\n",
    "    # For example, you can stop the loop when the change in weights is sufficiently small\n",
    "    # or when the loss function reaches a minimum threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more efficient version of Mini-batch Gradient Descent can be implemented with a few optimizations to reduce redundant computations, speed up execution, and improve memory usage. Below is an optimized version of your code that utilizes vectorized operations where possible and ensures efficient mini-batch sampling and gradient evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch Gradient Descent Implementation\n",
    "\n",
    "# Parameters\n",
    "batch_size = 256  # Size of the mini-batch (number of examples used in each iteration)\n",
    "\n",
    "while True:\n",
    "    # Sample a mini-batch of 256 training examples\n",
    "    # 'sample_training_data' is a function that randomly selects a batch of data points\n",
    "    data_batch = sample_training_data(data, batch_size)\n",
    "    \n",
    "    # Calculate the gradient of the loss function with respect to the weights\n",
    "    # 'evaluate_gradient' calculates the gradient for the mini-batch of data\n",
    "    gradient = evaluate_gradient(loss_fun, data_batch, weights)\n",
    "    \n",
    "    # Update the weights using the gradient and learning rate (step_size)\n",
    "    weights += -step_size * gradient  # Gradient update rule\n",
    "    \n",
    "    # Optional: Add a stopping condition based on the number of iterations or convergence\n",
    "    # For example, you can stop after a certain number of iterations or when the loss change is small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common values for batch size: 32, 128, and 256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Point: Loss Function Plotting**\n",
    "\n",
    "To ensure the correctness of the algorithm, **the loss function should be plotted** at different intervals during training, showing a decreasing trend over time. This will confirm that the algorithm is converging and minimizing the loss as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Gradient Descent Implementation\n",
    "\n",
    "# Set the condition for continuous updates (e.g., you can break this when convergence is met)\n",
    "##while True:\n",
    "    # Calculate the gradient of the loss function with respect to the weights\n",
    "    # 'evaluate_gradient' is a placeholder for the gradient calculation function\n",
    "    ##gradient = evaluate_gradient(lossfun, data, weights)\n",
    "    \n",
    "    # Update the weights by subtracting the gradient (scaled by the learning rate/step size)\n",
    "    ##weights += -step_size * gradient  # Gradient descent update rule\n",
    "\n",
    "    # Optional: Add a stopping condition based on a maximum number of iterations or convergence\n",
    "    # For example, you can stop the loop when the change in weights is sufficiently small\n",
    "    # or when the loss function reaches a minimum threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example GIF](https://i.sstatic.net/qAx2i.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example GIF](https://i.sstatic.net/1obtV.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation of errors\n",
    "\n",
    "***an algorithm for supervised learning of artificial neural networks using gradient descent***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Computation and Backpropagation\n",
    "\n",
    "So far, we've defined a **scoring function** where, for each input, we assign scores based on the weights (**W**) for each class. Using these scores, we define a **loss** for each data point. \n",
    "\n",
    "One of these loss functions is the **hinge loss**, and we also introduced another loss function called **logistic regression**. By averaging the losses of all the data points in the training set, we calculate the **overall loss**, which tells us how poorly the weights (**W**) are performing:\n",
    "- The **higher the loss**, the worse **W** is.\n",
    "- The **lower the loss**, the better.\n",
    "\n",
    "Additionally, we discussed another term known as **regularization**, which helps us predict well even for new data.\n",
    "\n",
    "To use the **gradient descent algorithm**, the only thing we need to do is compute the **gradient** of the loss function with respect to the **W** parameters. \n",
    "\n",
    "### The Challenge of Gradient Computation\n",
    "We can take derivatives from simpler functions. However, the issue arises when:\n",
    "- The function becomes **too complex**, with **nested structures** and **numerous parameters**.\n",
    "- In some cases, there might even be **millions of parameters**, making it impractical to manually derive each one using mathematical formulas.\n",
    "\n",
    "### The Solution: Backpropagation\n",
    "To handle this, we require an **automatic method** to compute these gradients efficiently. This is precisely where the **backpropagation algorithm** comes into play, allowing us to perform these computations automatically and systematically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example GIF](https://miro.medium.com/v2/resize:fit:1280/format:webp/1*VF9xl3cZr2_qyoLfDJajZw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
